{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Use pyDataverse to migrate data into Dataverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "European Dataverse Workshop @ Tromso\n",
    "\n",
    "Trainer: Stefan Kasberger from [AUSSDA - The Austrian Social Science Data Archive](https://aussda.at).\n",
    "[GitHub Repository](https://github.com/AUSSDA/european-dataverse-workshop-tromso)\n",
    "\n",
    "* [pyDataverse](https://github.com/AUSSDA/pyDataverse) ([develop](https://github.com/AUSSDA/pyDataverse/tree/develop))\n",
    "\n",
    "\n",
    "[Documentation Dataverse API](http://guides.dataverse.org/en/latest/api/index.html). pyDataverse mostly uses the native API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "What we will do:\n",
    "\n",
    "* Get a short introduction into the idea of pyDataverse (DONE)\n",
    "* Prepare the environment for the data migration:\n",
    "  * Get and run docker container for Jupyter Notebook\n",
    "  * Install pyDataverse\n",
    "  * Get pyDataverse templates for Datasets and Datafiles\n",
    "* Explain the pyDataverse templates and its usage\n",
    "* Import the data from the pyDataverse templates into pyDataverse\n",
    "* Upload the data via the API to our Dataverse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction pyDataverse\n",
    "\n",
    "See the [slides](https://github.com/AUSSDA/european-dataverse-workshop-tromso/presentation.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open your local terminal.\n",
    "\n",
    "SCREENSHOT\n",
    "Empty Shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and start Docker container for Jupyter notebook ([jupyter/datascience-notebook](https://hub.docker.com/r/jupyter/datascience-notebook)).\n",
    "\n",
    "```shell\n",
    "$ docker run -p 8888:8888 jupyter/scipy-notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCREENSHOT\n",
    "Command, Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go into the bash of the Docker container:\n",
    "\n",
    "```shell\n",
    "$ docker ps\n",
    "$ docker exec -it CONTAINER_ID bash\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCREENSHOT\n",
    "Command, Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are inside, you can install [pydataverse](https://github.com/AUSSDA/pyDataverse). To have the latest features, we install from the develop branch.\n",
    "\n",
    "```shell\n",
    "$ pip install git+https://github.com/aussda/pyDataverse.git@develop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCREENSHOT\n",
    "Command, Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can download the [pyDataverse templates from GitHub](https://github.com/AUSSDA/pyDataverse_templates), which are needed for the import:\n",
    "\n",
    "```shell\n",
    "$ cd work/\n",
    "$ git clone https://github.com/AUSSDA/pyDataverse_templates.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCREENSHOT\n",
    "Command, Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we download the [GitHub Repository for this workshop](https://github.com/AUSSDA/pyDataverse_workshop_tromso), with the Jupyter Notebook inside, prepared for this workshop.\n",
    "\n",
    "```shell\n",
    "$ git clone https://github.com/AUSSDA/pyDataverse_workshop_tromso.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCREENSHOT\n",
    "Command, Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Open Jupyter Notebook `localhost:8888`.\n",
    "* Open `work/pyDataverse_workshop_tromso/pydataverse.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything is installed and up and running, so we can move on to get our hands on some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pyDataverse templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-7a85d3a64840>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-7a85d3a64840>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    * Show templates empty\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "* Show templates empty\n",
    "* show prepared dataset.csv and datafile.csv\n",
    "* Beziehung Datasets und Datafiles erklären\n",
    "* Text abändern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the pyDataverse template files into pyDataverse\n",
    "\n",
    "After we added some data to the pyDataverse template files (datasets.csv, datafiles.csv), we can import the containing data into pyDataverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pyDataverse functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pyDataverse functionality\n",
    "from pyDataverse.models import Datafile\n",
    "from pyDataverse.models import Dataset\n",
    "from pyDataverse.utils import read_csv_to_dict\n",
    "from pyDataverse.utils import read_file\n",
    "from pyDataverse.utils import read_json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* Show data in pyDataverse\n",
    "* add license, ToU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-20-b9bcae04e459>\", line 1, in <module>\n",
      "    print(os.path.abspath('pydataverse.ipynb'))\n",
      "  File \"/opt/conda/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/opt/conda/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "print(os.path.abspath('pydataverse.ipynb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-2b20a4a2c737>\", line 1, in <module>\n",
      "    notebook_path = os.path.abspath('pydataverse.ipynb')\n",
      "  File \"/opt/conda/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/opt/conda/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "notebook_path = os.path.abspath('pydataverse.ipynb')\n",
    "ds_filename = s.path.join(os.path.dirname(notebook_path), 'datasets.csv')\n",
    "print(ds_filename)\n",
    "license_filename = s.path.join(os.path.dirname(notebook_path), 'license.html')\n",
    "terms_filename = s.path.join(os.path.dirname(notebook_path), 'terms-of-access.html')\n",
    "\n",
    "data = {}\n",
    "license_default = read_file(license_filename)\n",
    "for dataset in ds_filename:\n",
    "    print(dataset)\n",
    "    ds_tmp = {}\n",
    "    #print(os.getcwd())\n",
    "    \n",
    "    ds_tmp['termsOfAccess'] = read_file(terms_filename)\n",
    "    for key, val in dataset.items():\n",
    "        print(key, val)\n",
    "        if not val == '':\n",
    "            if key == 'aussda.dataset_id':\n",
    "                ds_id = val\n",
    "            elif key == 'dataverse.title':\n",
    "                ds_tmp['title'] = val\n",
    "            elif key == 'dataverse.subtitle':\n",
    "                ds_tmp['subtitle'] = val\n",
    "            elif key == 'dataverse.author':\n",
    "                ds_tmp['author'] = val\n",
    "            elif key == 'dataverse.dsDescription':\n",
    "                ds_tmp['dsDescription'] = []\n",
    "                ds_tmp['dsDescription'].append({\n",
    "                    'dsDescriptionValue': val})\n",
    "            elif key == 'dataverse.keywordValue':\n",
    "                ds_tmp['keyword'] = val\n",
    "            elif key == 'dataverse.topicClassification':\n",
    "                ds_tmp['topicClassification'] = val\n",
    "            elif key == 'dataverse.language':\n",
    "                ds_tmp['language'] = val\n",
    "            elif key == 'dataverse.subject':\n",
    "                ds_tmp['subject'] = []\n",
    "                ds_tmp['subject'].append(val)\n",
    "            elif key == 'dataverse.kindOfData':\n",
    "                ds_tmp['kindOfData'] = val.split(SEPERATOR)\n",
    "            elif key == 'dataverse.datasetContact':\n",
    "                ds_tmp['datasetContact'] = val\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filename = 'datafiles.csv'\n",
    "\n",
    "for datafile in datafiles_csv:\n",
    "    df_tmp = {}\n",
    "    df_id = None\n",
    "    ds_id = None\n",
    "    for key, val in datafile.items():\n",
    "        if not val == '':\n",
    "            if key == 'description' or key == 'filename':\n",
    "                df_tmp[key] = val\n",
    "            elif key == 'aussda.datafile_id':\n",
    "                df_tmp['datafile_id'] = val\n",
    "                df_id = val\n",
    "            elif key == 'aussda.dataset_id':\n",
    "                ds_id = val\n",
    "                df_tmp['dataset_id'] = ds_id\n",
    "            elif key == 'dataverse.categories':\n",
    "                df_tmp['categories'] = val\n",
    "    df_tmp['restrict'] = True\n",
    "    if ds_id not in data:\n",
    "        data[ds_id] = {}\n",
    "    if 'datafiles' not in data[ds_id]:\n",
    "        data[ds_id]['datafiles'] = {}\n",
    "    if df_id not in data[ds_id]['datafiles']:\n",
    "        data[ds_id]['datafiles'][df_id] = {}\n",
    "    if 'metadata' not in data[ds_id]['datafiles'][df_id]:\n",
    "        data[ds_id]['datafiles'][df_id]['metadata'] = {}\n",
    "    data[ds_id]['datafiles'][df_id]['metadata'] = df_tmp\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()\n",
    "ds.import_metadata(ds_filename)\n",
    "ds.title\n",
    "ds.description\n",
    "ds.dict()\n",
    "ds.json()\n",
    "\n",
    "df = Datafile()\n",
    "df.dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store metadata as JSON\n",
    "\n",
    "save json locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data to Dataverse via API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to get an API token for the Dataverse API. Go to [localhost:8085]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_token = 'SECRET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api_token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f6fabb2bce90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdataverse_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://localhost:8085'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataverse_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'api_token' is not defined"
     ]
    }
   ],
   "source": [
    "# load pyDataverse functionality\n",
    "from pyDataverse.api import Api\n",
    "\n",
    "# set dataverse url\n",
    "dataverse_url = 'http://localhost:8085'\n",
    "\n",
    "api = Api(dataverse_url, api_token)\n",
    "api.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dataverse, in which the dataset should be created\n",
    "dv_alias = 'root'\n",
    "\n",
    "resp = api.get_dataverse(dv_alias)\n",
    "resp.json()\n",
    "resp = api.create_dataset(dv_alias, ds.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View created Dataset at localhost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.upload_datafile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View uploaded Datafiles at localhost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
